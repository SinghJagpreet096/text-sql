{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: ['department_management How many heads of the departments are older than 56 ?', 'department_management List the name, born state and age of the heads of departments ordered by age.']\n",
      "y_train: ['SELECT count(*) FROM head WHERE age  >  56', 'SELECT name ,  born_state ,  age FROM head ORDER BY age']\n",
      "[28414, 46463, 2650, 1690, 14971, 315, 279, 26280, 527, 9191, 1109, 220, 3487, 949]\n",
      "[28414, 46463, 1796, 279, 836, 11, 9405, 1614, 323, 4325, 315, 279, 14971, 315, 26280, 11713, 555, 4325, 13]\n",
      "[28414, 46463, 1796, 279, 9886, 1060, 11, 836, 323, 8199, 315, 1855, 9476, 13]\n",
      "[28414, 46463, 3639, 527, 279, 7340, 323, 8187, 8199, 315, 279, 26280, 30]\n",
      "[28414, 46463, 3639, 374, 279, 5578, 1396, 315, 8420, 315, 279, 26280, 6832, 7222, 374, 1990, 220, 605, 323, 220, 868, 30]\n",
      "[28414, 46463, 3639, 527, 279, 5144, 315, 279, 14971, 889, 527, 9405, 4994, 279, 7188, 1614, 30]\n",
      "[28414, 46463, 3639, 527, 279, 12742, 9886, 1667, 315, 279, 26280, 9152, 555, 264, 19607, 9405, 304, 1614, 364, 98911, 71090]\n",
      "[28414, 46463, 3639, 527, 279, 5144, 315, 279, 5415, 1405, 520, 3325, 220, 18, 14971, 1051, 9405, 30]\n",
      "[28414, 46463, 763, 902, 1060, 1051, 1455, 26280, 9749, 30]\n",
      "[28414, 46463, 7073, 279, 836, 323, 1396, 315, 8420, 369, 279, 26280, 9152, 555, 14971, 6832, 13643, 15718, 907, 374, 364, 9642, 71090]\n",
      "[28414, 46463, 2650, 1690, 15718, 60458, 527, 1070, 30]\n",
      "vocab_size: 100277\n",
      "\n",
      "X_train_padded[[28414 46463  2650  1690 14971   315   279 26280   527  9191  1109   220\n",
      "   3487   949     0     0     0     0     0     0     0     0     0]\n",
      " [28414 46463  1796   279   836    11  9405  1614   323  4325   315   279\n",
      "  14971   315 26280 11713   555  4325    13     0     0     0     0]]\n",
      "\n",
      "y_train_padded: [[ 4963  1797 29771  4393  2010  5401  4325   220   871   220   220  3487\n",
      "      0     0     0     0     0     0     0     0     0     0     0]\n",
      " [ 4963   836  1174   220  9405  4486  1174   220  4325  4393  2010 15888\n",
      "   7866  4325     0     0     0     0     0     0     0     0     0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense,Masking\n",
    "\n",
    "import mlflow\n",
    "\n",
    "\n",
    "\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "def load_data(file_path):\n",
    "    selected_columns = [\"db_id\",\"question\",\"query\"]\n",
    "    df = pd.read_parquet(file_path,columns=selected_columns)\n",
    "    X_train = df[[\"db_id\",\"question\"]]\n",
    "    y_train = df[[\"query\"]]\n",
    "    return X_train,y_train\n",
    "\n",
    "X_train, y_train = load_data(\"~/ML_Projects/text-sql/data/train/0000.parquet\")\n",
    "\n",
    "X_train['question'] = (X_train[\"db_id\"] +\" \"+ X_train['question'])\n",
    "X_train = X_train.drop('db_id',axis=1)\n",
    "y_train = y_train['query'].to_list()\n",
    "X_train = X_train['question'].to_list()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f'X_train: {X_train[:2]}')\n",
    "print(f'y_train: {y_train[:2]}')\n",
    "\n",
    "\n",
    "X_train_sequences = []\n",
    "for sent in X_train[:11]:\n",
    "    print(enc.encode(sent))\n",
    "    X_train_sequences.append(enc.encode(sent))\n",
    "X_train_padded = pad_sequences(X_train_sequences, padding='post')\n",
    "y_train_sequences = []\n",
    "for sent in y_train[:11]:\n",
    "    y_train_sequences.append(enc.encode(sent))\n",
    "y_train_padded = pad_sequences(y_train_sequences, padding='post',maxlen=X_train_padded.shape[1])\n",
    "\n",
    "vocab_size_enc = enc.n_vocab\n",
    "print(f'vocab_size: {vocab_size_enc}\\n')\n",
    "print(f'X_train_padded{X_train_padded[:2]}\\n')\n",
    "print(f\"y_train_padded: {y_train_padded[:2]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "log_param() missing 1 required positional argument: 'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# print(params.keys())\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mlflow\u001b[38;5;241m.\u001b[39mstart_run():\n\u001b[0;32m---> 21\u001b[0m     \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_param\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Assuming 0 is the padding value\u001b[39;00m\n\u001b[1;32m     25\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[1;32m     26\u001b[0m     Masking(mask_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m     27\u001b[0m     Embedding(input_dim\u001b[38;5;241m=\u001b[39mvocab_size_enc, output_dim\u001b[38;5;241m=\u001b[39membedding_dim),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m     Dense(units\u001b[38;5;241m=\u001b[39mvocab_size_enc, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     31\u001b[0m ])\n",
      "\u001b[0;31mTypeError\u001b[0m: log_param() missing 1 required positional argument: 'value'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Masking, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "embedding_dim = 128\n",
    "units = 128\n",
    "params = {'input_dim':vocab_size_enc,\n",
    "          'output_dim':embedding_dim,\n",
    "          'units':units,\n",
    "          'activation':'softmax',\n",
    "          'optimizer':'adam',\n",
    "          'loss':'sparse_categorical_crossentropy',\n",
    "          'metrics':'accuracy'\n",
    "          }\n",
    "\n",
    "# print(params.keys())\n",
    "# with mlflow.start_run():\n",
    "#     mlflow.log_param(params)\n",
    "    \n",
    "\n",
    "# Assuming 0 is the padding value\n",
    "model = Sequential([\n",
    "    Masking(mask_value=0),\n",
    "    Embedding(input_dim=vocab_size_enc, output_dim=embedding_dim),\n",
    "    LSTM(units, return_sequences=True),\n",
    "    # Dropout(0.2),  # Adjust the dropout rate as needed\n",
    "    Dense(units=vocab_size_enc, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model with Dropout and EarlyStopping\n",
    "history = model.fit(\n",
    "    X_train_padded,\n",
    "    y_train_padded,\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    validation_split=0.3,\n",
    "    callbacks=[early_stopping]  # Add EarlyStopping callback\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sql(question,padding_index = 0):\n",
    "\n",
    "    question_sequence = enc.encode(question)\n",
    "    # print(f\"question_sequence: {question_sequence}\")\n",
    "    question_padded = pad_sequences([question_sequence], padding='post')\n",
    "    # print(f\"question_padded: {question_padded}\")\n",
    "    predicted_sequence = model.predict(question_padded)\n",
    "    # print(f\"predicted_sequence: {predicted_sequence}\")\n",
    "    predicted_indices = np.argmax(predicted_sequence, axis=-1)\n",
    "    predicted_indices[predicted_sequence.argmax(axis=-1) == padding_index] = padding_index\n",
    "    predicted_query = enc.decode(predicted_indices[0])\n",
    "    # predicted_sql_query = enc.decode(predicted_sequence)\n",
    "    return predicted_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(generate_sql(\"How many heads of the departments are older than 56 ?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val,y_val = load_data('/Users/jagpreetsingh/ML_Projects/text-sql/data/validation/validation-00000-of-00001.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(            db_id                                           question\n",
       " 0  concert_singer                       How many singers do we have?\n",
       " 1  concert_singer               What is the total number of singers?\n",
       " 2  concert_singer  Show name, country, age for all singers ordere...\n",
       " 3  concert_singer  What are the names, countries, and ages for ev...\n",
       " 4  concert_singer  What is the average, minimum, and maximum age ...,\n",
       "                                                query\n",
       " 0                        SELECT count(*) FROM singer\n",
       " 1                        SELECT count(*) FROM singer\n",
       " 2  SELECT name ,  country ,  age FROM singer ORDE...\n",
       " 3  SELECT name ,  country ,  age FROM singer ORDE...\n",
       " 4  SELECT avg(age) ,  min(age) ,  max(age) FROM s...)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.head(), y_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "# # Calculate BLEU score for each pair of true and generated queries\n",
    "# bleu_scores = [sentence_bleu([true_query.split()], generated_query.split()) for true_query, generated_query in zip(y_test, decoded_predictions)]\n",
    "\n",
    "# # Print average BLEU score\n",
    "# average_bleu_score = sum(bleu_scores) / len(bleu_scores)\n",
    "# print(f\"Average BLEU Score: {average_bleu_score}\")\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
