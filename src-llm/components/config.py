GPT_CONFIG_124M = {
    "vocab_size" : 50257, # vocabulary size
    "ctx_len" : 32,     # context length
    "emb_dim" : 6,      # embedding dimesension
    "n_head" : 3,        # number of attention heads
    "n_layers" : 3,      # number of layers
    "drop_rate" : 0.1,    # Dropout rate
    "qkv_bias" : False
}